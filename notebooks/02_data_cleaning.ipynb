{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cffe995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda87ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrolment shape: (1006029, 7)\n",
      "Demographic shape: (2071700, 6)\n",
      "Biometric shape: (1861108, 6)\n"
     ]
    }
   ],
   "source": [
    "enrol = pd.read_csv(\"../data/processed/enrolment_full.csv\")\n",
    "demo = pd.read_csv(\"../data/processed/demographic_full.csv\")\n",
    "bio = pd.read_csv(\"../data/processed/biometric_full.csv\")\n",
    "\n",
    "print(\"Enrolment shape:\", enrol.shape)\n",
    "print(\"Demographic shape:\", demo.shape)\n",
    "print(\"Biometric shape:\", bio.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c70f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Enrolment:\n",
      " date              0\n",
      "state             0\n",
      "district          0\n",
      "pincode           0\n",
      "age_0_5           0\n",
      "age_5_17          0\n",
      "age_18_greater    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Demographic:\n",
      " date             0\n",
      "state            0\n",
      "district         0\n",
      "pincode          0\n",
      "demo_age_5_17    0\n",
      "demo_age_17_     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Biometric:\n",
      " date            0\n",
      "state           0\n",
      "district        0\n",
      "pincode         0\n",
      "bio_age_5_17    0\n",
      "bio_age_17_     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in Enrolment:\\n\", enrol.isnull().sum())\n",
    "print(\"\\nMissing values in Demographic:\\n\", demo.isnull().sum())\n",
    "print(\"\\nMissing values in Biometric:\\n\", bio.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc0230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [enrol, demo, bio]:\n",
    "    # Fix date format (DD-MM-YYYY)\n",
    "    df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "    \n",
    "    # Clean text columns\n",
    "    df['state'] = df['state'].astype(str).str.title().str.strip()\n",
    "    df['district'] = df['district'].astype(str).str.title().str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58e728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:\n",
      "Enrolment: (983000, 7)\n",
      "Demographic: (1598012, 6)\n",
      "Biometric: (1766159, 6)\n"
     ]
    }
   ],
   "source": [
    "enrol = enrol.dropna(subset=['date'])\n",
    "demo = demo.dropna(subset=['date'])\n",
    "bio = bio.dropna(subset=['date'])\n",
    "\n",
    "enrol.drop_duplicates(inplace=True)\n",
    "demo.drop_duplicates(inplace=True)\n",
    "bio.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"Enrolment:\", enrol.shape)\n",
    "print(\"Demographic:\", demo.shape)\n",
    "print(\"Biometric:\", bio.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f3d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cols_enrol = ['age_0_5', 'age_5_17', 'age_18_greater']\n",
    "demo_cols = ['demo_age_5_17', 'demo_age_17_']\n",
    "bio_cols = ['bio_age_5_17', 'bio_age_17_']\n",
    "\n",
    "for col in age_cols_enrol:\n",
    "    enrol[col] = pd.to_numeric(enrol[col], errors='coerce').fillna(0)\n",
    "\n",
    "for col in demo_cols:\n",
    "    demo[col] = pd.to_numeric(demo[col], errors='coerce').fillna(0)\n",
    "\n",
    "for col in bio_cols:\n",
    "    bio[col] = pd.to_numeric(bio[col], errors='coerce').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0941c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrol['total_enrol'] = enrol[age_cols_enrol].sum(axis=1)\n",
    "demo['total_demo_updates'] = demo[demo_cols].sum(axis=1)\n",
    "bio['total_bio_updates'] = bio[bio_cols].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7303907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned datasets saved successfully!\n"
     ]
    }
   ],
   "source": [
    "enrol.to_csv(\"../data/processed/enrolment_clean.csv\", index=False)\n",
    "demo.to_csv(\"../data/processed/demographic_clean.csv\", index=False)\n",
    "bio.to_csv(\"../data/processed/biometric_clean.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned datasets saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3455aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found: enrolment_clean.csv\n",
      "âœ… Found: demographic_clean.csv\n",
      "âœ… Found: biometric_clean.csv\n",
      "------------------------------\n",
      "âœ… SUCCESS! Master file created at: ../data/processed/master_aadhaar_data.csv\n",
      "Total rows for Power BI: 13007\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "path_prefix = \"../data/processed/\"\n",
    "\n",
    "# Verify files exist before loading\n",
    "files_to_check = [\"enrolment_clean.csv\", \"demographic_clean.csv\", \"biometric_clean.csv\"]\n",
    "for file in files_to_check:\n",
    "    if not os.path.exists(os.path.join(path_prefix, file)):\n",
    "        print(f\"âŒ Error: {file} not found in {path_prefix}\")\n",
    "    else:\n",
    "        print(f\"âœ… Found: {file}\")\n",
    "\n",
    "# STEP 2: LOAD CLEANED DATA \n",
    "enrol = pd.read_csv(f\"{path_prefix}enrolment_clean.csv\")\n",
    "demo = pd.read_csv(f\"{path_prefix}demographic_clean.csv\")\n",
    "bio = pd.read_csv(f\"{path_prefix}biometric_clean.csv\")\n",
    "\n",
    "# STEP 3: DATE CONVERSION & MONTHLY AGGREGATION \n",
    "for df in [enrol, demo, bio]:\n",
    "    # Ensure date is in datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "    # Create month column for Power BI time-series filtering\n",
    "    df['month'] = df['date'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Group by state, district, and month to keep the file size manageable\n",
    "enrol_agg = enrol.groupby(['state', 'district', 'month'])[['total_enrol']].sum().reset_index()\n",
    "demo_agg = demo.groupby(['state', 'district', 'month'])[['total_demo_updates']].sum().reset_index()\n",
    "bio_agg = bio.groupby(['state', 'district', 'month'])[['total_bio_updates']].sum().reset_index()\n",
    "\n",
    "#STEP 4: MERGE DATASETS\n",
    "master = enrol_agg.merge(demo_agg, on=['state', 'district', 'month'], how='outer').fillna(0)\n",
    "master = master.merge(bio_agg, on=['state', 'district', 'month'], how='outer').fillna(0)\n",
    "\n",
    "#STEP 5: CALCULATE PRIZE-WINNING METRICS \n",
    "master['total_updates'] = master['total_demo_updates'] + master['total_bio_updates']\n",
    "# Service Ratio: High numbers indicate districts with heavy update pressure\n",
    "master['service_ratio'] = master['total_updates'] / (master['total_enrol'] + 1)\n",
    "\n",
    "# STEP 6: SAVE FINAL MASTER FILE \n",
    "output_path = f\"{path_prefix}master_aadhaar_data.csv\"\n",
    "master.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"âœ… SUCCESS! Master file created at: {output_path}\")\n",
    "print(f\"Total rows for Power BI: {len(master)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea239e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ FINAL CLEANING COMPLETE!\n",
      "Unique States remaining: 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the file you just created\n",
    "df = pd.read_csv(\"../data/processed/master_aadhaar_data.csv\")\n",
    "\n",
    "# 1. Remove noise rows (numeric names)\n",
    "df = df[~df['state'].str.contains('100000', na=False)]\n",
    "\n",
    "# 2. Standardize State Names (Mapping duplicates)\n",
    "state_map = {\n",
    "    \"Andaman & Nicobar Islands\": \"Andaman And Nicobar Islands\",\n",
    "    \"Orissa\": \"Odisha\",\n",
    "    \"West Bangal\": \"West Bengal\",\n",
    "    \"West  Bengal\": \"West Bengal\",\n",
    "    \"West Bengli\": \"West Bengal\",\n",
    "    \"Westbengal\": \"West Bengal\",\n",
    "    \"Chhatisgarh\": \"Chhattisgarh\",\n",
    "    \"Uttaranchal\": \"Uttarakhand\",\n",
    "    \"Pondicherry\": \"Puducherry\"\n",
    "}\n",
    "df['state'] = df['state'].replace(state_map)\n",
    "\n",
    "# 3. Clean up extra spaces in names\n",
    "df['state'] = df['state'].str.strip()\n",
    "df['district'] = df['district'].str.strip()\n",
    "\n",
    "# 4. Handle NaT in months\n",
    "df['month'] = df['month'].fillna(\"Unknown\")\n",
    "\n",
    "# 5. Filter out any rows that are completely zero (no activity)\n",
    "df = df[df['total_updates'] + df['total_enrol'] > 0]\n",
    "\n",
    "# Save the FINAL polished version\n",
    "df.to_csv(\"../data/processed/final_aadhaar_dashboard_data.csv\", index=False)\n",
    "\n",
    "print(\"ðŸš€ FINAL CLEANING COMPLETE!\")\n",
    "print(f\"Unique States remaining: {df['state'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
